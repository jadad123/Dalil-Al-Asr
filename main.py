import requests
import feedparser
import json
import time
import base64
import sqlite3
import os
import re
import urllib.parse
import io
import urllib3
import random
import httpx
from openai import OpenAI
from datetime import datetime
from difflib import SequenceMatcher
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±" (V3 - Long Content)
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

OPENROUTER_KEY = os.getenv("OPENROUTER_KEY", "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")

WP_DOMAIN = os.getenv("WP_DOMAIN", "https://dalil-alasr.com") 
WP_USER = os.getenv("WP_USER", "admin")
WP_APP_PASS = os.getenv("WP_APP_PASS", "xxxx xxxx xxxx xxxx")

WP_ENDPOINT = f"{WP_DOMAIN}/wp-json/wp/v2"
SITE_NAME_WATERMARK = "Dalil Al-Asr"

BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
    "Referer": "https://google.com"
}

# Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Ù‚ÙˆÙŠØ© ÙÙ‚Ø· Ù„Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
FREE_TEXT_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "qwen/qwen-2.5-72b-instruct:free", 
    "deepseek/deepseek-chat:free"
]

FREE_VISION_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.2-90b-vision-instruct:free",
]

BLACKLIST_KEYWORDS = [
    "ÙÙŠÙ„Ù…", "Ù…Ø³Ù„Ø³Ù„", "Ø£ØºÙ†ÙŠØ©", "ÙÙ†Ø§Ù†", "Ù…Ù…Ø«Ù„Ø©", "Ø±Ù‚Øµ", "Ø­ÙÙ„ ØºÙ†Ø§Ø¦ÙŠ", 
    "Ø³ÙŠÙ†Ù…Ø§", "Ø¯Ø±Ø§Ù…Ø§", "Ø·Ø±Ø¨", "Ø£Ù„Ø¨ÙˆÙ…", "ÙƒÙ„ÙŠØ¨", "ÙØ¶Ø§Ø¦ÙŠØ§Øª", 
    "Movie", "Song", "Actress", "Cinema", "Music Video", "Concert"
]

DB_FILE = "/app/data/dalil_history.db" if os.path.exists("/app") else "dalil_history.db"

# ==========================================
# 1. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
# ==========================================
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (link TEXT PRIMARY KEY, title TEXT, published_at TEXT)''')
    conn.commit()
    conn.close()

def is_published_link(link):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT 1 FROM history WHERE link=?", (link,))
    exists = c.fetchone()
    conn.close()
    return exists is not None

def mark_published(link, title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO history VALUES (?, ?, ?)", (link, title, datetime.now().isoformat()))
    conn.commit()
    conn.close()

def is_duplicate_semantic(new_title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT title FROM history ORDER BY published_at DESC LIMIT 50")
    rows = c.fetchall()
    conn.close()
    if not rows: return False
    recent_titles = [row[0] for row in rows if row[0]]
    for existing in recent_titles:
        if SequenceMatcher(None, new_title.lower(), existing.lower()).ratio() > 0.65:
            return True
    return False

# ==========================================
# 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
# ==========================================
def get_auth_header():
    clean_pass = WP_APP_PASS.replace(' ', '')
    creds = base64.b64encode(f"{WP_USER}:{clean_pass}".encode()).decode()
    return {"Authorization": f"Basic {creds}", "Content-Type": "application/json"}

def get_category_id_by_name(cat_name):
    ARABIC_NAMES = {
        "News": "Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù…Ø©", "Politics": "Ø³ÙŠØ§Ø³Ø©", "Economy": "Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ£Ø¹Ù…Ø§Ù„",
        "Crypto": "Ø¹Ù…Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ©", "Tech": "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙˆØ°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", 
        "Health": "ØµØ­Ø© ÙˆØ·Ø¨", "Science": "Ø¹Ù„ÙˆÙ… ÙˆÙØ¶Ø§Ø¡", "Tutorials": "Ø´Ø±ÙˆØ­Ø§Øª ÙˆØ£Ø¯Ù„Ø©",
        "Sports": "Ø±ÙŠØ§Ø¶Ø©"
    }
    final_name = ARABIC_NAMES.get(cat_name, cat_name)
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/categories?search={final_name}", headers=h)
        if r.status_code == 200 and r.json():
            return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/categories", headers=h, json={"name": final_name})
        if r.status_code == 201:
            return r.json()['id']
    except: pass
    return 1

def get_or_create_tag_id(tag_name):
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/tags?search={tag_name}", headers=h)
        if r.status_code == 200 and r.json(): return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/tags", headers=h, json={"name": tag_name})
        if r.status_code == 201: return r.json()['id']
    except: pass
    return None

# ==========================================
# 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
# ==========================================
def get_ai_image_url(title):
    clean_title = re.sub(r'[^\w\s]', '', title)
    words = clean_title.split()[:9]
    prompt_text = " ".join(words)
    final_prompt = f"Editorial news photo of {prompt_text}, highly detailed, realistic, 4k, journalism style, no text, no blur"
    encoded_prompt = urllib.parse.quote(final_prompt)
    seed = int(time.time())
    return f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1280&height=720&nologo=true&seed={seed}&model=flux"

def check_image_safety(image_url):
    print(f"   ğŸ” Checking watermark in original...")
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=OPENROUTER_KEY, http_client=http_client)
    for i in range(3):
        model = random.choice(FREE_VISION_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": [{"type": "text", "text": "Does this image contain ANY text, logos, or watermarks? Answer strictly 'YES' or 'NO'."}, {"type": "image_url", "image_url": {"url": image_url}}]}]
            )
            return "NO" in response.choices[0].message.content.strip().upper()
        except: time.sleep(1)
    return False

def apply_branding(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        bar_height = int(height * 0.08) 
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(0, 0, 0, 160))
        try: 
            font_size = int(bar_height * 0.6)
            try: font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
            except: font = ImageFont.load_default()
        except: return image_bytes
        text = SITE_NAME_WATERMARK
        text_x = width / 2 - (len(text) * 5) 
        text_y = height - (bar_height * 0.8)
        draw.text((text_x, text_y), text, font=font, fill=(255, 255, 255, 255))
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=92)
        return output.getvalue()
    except: return image_bytes

def upload_final_image(img_url, alt_text):
    print(f"   â¬†ï¸ Downloading & Branding Image...")
    try:
        r_img = requests.get(img_url, headers=BROWSER_HEADERS, timeout=30, verify=False)
        if r_img.status_code == 200:
            branded_image_data = apply_branding(r_img.content)
            filename = f"dalil_{int(time.time())}.jpg"
            headers_wp = get_auth_header()
            headers_wp["Content-Disposition"] = f"attachment; filename={filename}"
            headers_wp["Content-Type"] = "image/jpeg"
            r_wp = requests.post(f"{WP_ENDPOINT}/media", headers=headers_wp, data=branded_image_data)
            if r_wp.status_code == 201: 
                media_id = r_wp.json()['id']
                seo_data = {
                    "alt_text": alt_text, "title": alt_text, 
                    "caption": f"Ø­Ù‚ÙˆÙ‚ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù€ {SITE_NAME_WATERMARK}", "description": alt_text
                }
                requests.post(f"{WP_ENDPOINT}/media/{media_id}", headers=get_auth_header(), json=seo_data)
                return media_id
    except: pass
    return None

def extract_image(entry):
    if hasattr(entry, 'media_content') and entry.media_content:
        return entry.media_content[0].get('url') if isinstance(entry.media_content[0], dict) else entry.media_content[0]['url']
    if hasattr(entry, 'links') and entry.links:
        for l in entry.links:
            if 'image' in getattr(l, 'type', ''): return getattr(l, 'href', None)
    if hasattr(entry, 'summary'):
        m = re.search(r'<img.*?src=["\']([^"\']+)["\']', entry.summary)
        if m: return m.group(1)
    return None

# ==========================================
# 4. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ù…Ø­ØªÙˆÙ‰ Ø·ÙˆÙŠÙ„ + Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ)
# ==========================================
def generate_arabic_content_package(news_item):
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=OPENROUTER_KEY, http_client=http_client)
    
    # ğŸ’¥ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ø·Ù„Ø¨ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ + Ù…Ù‚Ø§Ù„ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹
    prompt = f"""
    Ø¨ØµÙØªÙƒ ÙƒØ¨ÙŠØ± Ù…Ø­Ø±Ø±ÙŠ "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±"ØŒ Ù‚Ù… Ø¨ØµÙŠØ§ØºØ© Ù…Ù‚Ø§Ù„ ØµØ­ÙÙŠ Ø´Ø§Ù…Ù„ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
    
    Ø§Ù„Ù…ØµØ¯Ø±: "{news_item['title']}" - {news_item['summary']}

    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø¯Ù‚Ø©:
    1. **Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** Ø§ÙƒØªØ¨ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ø¹Ø±Ø¨ÙŠØ§Ù‹ Ø¬Ø°Ø§Ø¨Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ (Clickbait Ù†Ø¸ÙŠÙ) ÙÙŠ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø¹Ø¯ ÙƒÙ„Ù…Ø© ARABIC_TITLE:.
    2. **Ø§Ù„Ù…Ø­ØªÙˆÙ‰:** Ù…Ù‚Ø§Ù„ Ø·ÙˆÙŠÙ„ (Ù„Ø§ ÙŠÙ‚Ù„ Ø¹Ù† 800 ÙƒÙ„Ù…Ø©). ÙŠØ¬Ø¨ Ø£Ù† ØªØªÙˆØ³Ø¹ ÙÙŠ Ø§Ù„Ø´Ø±Ø­ØŒ ÙˆØªØ¶ÙŠÙ Ø³ÙŠØ§Ù‚Ø§Ù‹ØŒ ÙˆØªØ­Ù„ÙŠÙ„Ø§Ù‹ØŒ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ù…ØµØ¯Ø± Ù‚ØµÙŠØ±Ø§Ù‹.
    3. **Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©:**
       - **Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©:** Ù‚ÙˆÙŠØ© ØªØ´Ø¯ Ø§Ù„Ù‚Ø§Ø±Ø¦.
       - **Ø§Ù„ØªÙØ§ØµÙŠÙ„:** Ø§Ø³ØªØ®Ø¯Ù… <h2> Ù„Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ÙØ±Ø¹ÙŠØ© (Ù…Ø«Ù„Ø§Ù‹: Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©ØŒ Ù…Ø§Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ØŸØŒ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©).
       - **Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª:** Ù‚Ù… Ø¨ØµÙŠØ§ØºØ© Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø®Ø¨Ø± (Ù…Ø«Ù„Ø§Ù‹: "ÙˆÙŠØ±Ù‰ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡ Ø£Ù†...").
       - **Ø®Ø§ØªÙ…Ø©:** ØªÙ„Ø®ÙŠØµ ÙˆØªØ·Ù„Ø¹Ø§Øª Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©.
    4. **Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:** Ø§Ø³ØªØ®Ø¯Ù… HTML (Direction: RTL).
       - Ø£Ø¶Ù ØµÙ†Ø¯ÙˆÙ‚Ø§Ù‹ Ù…Ù…ÙŠØ²Ø§Ù‹: <div style="background-color: #f1f8e9; border-right: 5px solid #8bc34a; padding: 15px; margin: 20px 0;"><strong>ğŸ” Ø²Ø§ÙˆÙŠØ© ØªØ­Ù„ÙŠÙ„ÙŠØ©:</strong> ...</div>
    
    5. **Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© (ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©):**
       CATEGORY: [News, Politics, Economy, Crypto, Tech, Science, Health, Sports]
       TAGS: (5 ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø¹Ø±Ø¨ÙŠØ©)
       META_DESC: (ÙˆØµÙ Ø¯Ù‚ÙŠÙ‚ 150 Ø­Ø±Ù)

    ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
    ARABIC_TITLE: [Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†Ø§]
    [Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ù„ HTML Ù‡Ù†Ø§...]
    ...
    CATEGORY: Tech
    TAGS: ...
    META_DESC: ...
    """
    
    for i in range(5):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            print(f"   ğŸ¤– Writing Long Article with: {model}")
            response = client.chat.completions.create(
                model=model, messages=[{"role": "user", "content": prompt}], temperature=0.7 # Ø±ÙØ¹Ù†Ø§ Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„Ø¥Ø¨Ø¯Ø§Ø¹
            )
            content = response.choices[0].message.content.replace("```html", "").replace("```", "").strip()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
            arabic_title = news_item['title'] # Ø§ÙØªØ±Ø§Ø¶ÙŠ
            final_body = content
            
            if "ARABIC_TITLE:" in content:
                parts = content.split("\n", 1) # ÙØµÙ„ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ÙˆÙ„
                if "ARABIC_TITLE:" in parts[0]:
                    arabic_title = parts[0].replace("ARABIC_TITLE:", "").strip().replace('"', '')
                    final_body = parts[1].strip()
            
            return arabic_title, final_body
            
        except Exception as e:
            print(f"   âš ï¸ AI Error: {e}. Retrying...")
            time.sleep(3)
    return None, None

def publish_to_wp(arabic_title, content, feat_img_id):
    meta_desc, tags, cat_id = "", [], 1
    
    try:
        if "CATEGORY:" in content:
            parts = content.split("CATEGORY:")
            body_content = parts[0].strip()
            metadata = parts[1]
            
            cat_name = metadata.split("\n")[0].strip()
            cat_id = get_category_id_by_name(cat_name)
            
            if "TAGS:" in metadata:
                tags_part = metadata.split("TAGS:")[1].split("META_DESC:")[0]
                tags = [t.strip() for t in tags_part.split(",")]
            if "META_DESC:" in metadata:
                meta_desc = metadata.split("META_DESC:")[1].strip()
                
            content = body_content
    except: pass

    tag_ids = [get_or_create_tag_id(t) for t in tags if t]
    
    data = {
        "title": arabic_title, # Ø§Ù„Ø¢Ù† Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…ÙˆÙ„Ø¯
        "content": content, "status": "publish",
        "categories": [cat_id], "tags": tag_ids, "excerpt": meta_desc,
        "featured_media": feat_img_id,
        "rank_math_focus_keyword": tags[0] if tags else "Ø£Ø®Ø¨Ø§Ø±",
        "rank_math_description": meta_desc
    }
    data["meta"] = {"rank_math_focus_keyword": data["rank_math_focus_keyword"], "rank_math_description": meta_desc}
    
    r = requests.post(f"{WP_ENDPOINT}/posts", headers=get_auth_header(), json=data)
    if r.status_code == 201: return r.json()['link']
    print(f"   âŒ Publish Failed: {r.status_code}")
    return None

# ==========================================
# 5. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
def main():
    print("ğŸš€ Dalil Al-Asr (V3 - Long Arabic Content) Started...")
    init_db()
    
    feeds = [
        "https://cointelegraph.com/rss",
        "https://decrypt.co/feed",
        "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "https://sa.investing.com/rss/news.rss",
        "https://www.cnbcarabia.com/rss/latest-news",
        "https://techcrunch.com/feed/",
        "https://www.theverge.com/rss/index.xml",
        "https://aitnews.com/feed/",
        "https://wired.com/feed/rss",
        "https://www.unlimit-tech.com/feed/",
        "https://www.aljazeera.net/aljazeerarss/a7c186be-1baa-4bd4-9d80-a84db769f779/73d0e1b4-532f-45ef-b135-bfdff8b8cab9",
        "https://www.skynewsarabia.com/web/rss",
        "https://cnn.com/rss/cnn_topstories.rss",
        "https://feeds.bbci.co.uk/news/world/rss.xml",
        "https://www.sciencedaily.com/rss/top/health.xml",
        "https://www.nasa.gov/rss/dyn/breaking_news.rss"
    ]
    
    while True:
        print(f"\nâ° Cycle Start: {datetime.now().strftime('%H:%M')}")
        random.shuffle(feeds)
        
        for feed in feeds:
            try:
                d = feedparser.parse(feed)
                for entry in d.entries[:5]: 
                    if is_published_link(entry.link): continue
                    if any(bad in entry.title for bad in BLACKLIST_KEYWORDS): continue
                    if is_duplicate_semantic(entry.title): continue
                    
                    print(f"   âš¡ Processing: {entry.title[:40]}...")
                    
                    # 1. Ø§Ù„ØµÙˆØ±Ø©
                    original_img = extract_image(entry)
                    final_img_url = None
                    if original_img:
                        if check_image_safety(original_img):
                            print("   âœ… Original Clean.")
                            final_img_url = original_img
                        else:
                            print("   âš ï¸ Watermark detected. AI Gen...")
                            final_img_url = get_ai_image_url(entry.title)
                    else:
                        print("   ğŸ¨ AI Gen...")
                        final_img_url = get_ai_image_url(entry.title)
                    
                    fid = upload_final_image(final_img_url, entry.title)
                    
                    if fid:
                        # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø·ÙˆÙŠÙ„
                        arabic_title, content = generate_arabic_content_package({'title': entry.title, 'summary': getattr(entry, 'summary', '')})
                        
                        if content and arabic_title:
                            print(f"   ğŸ“ Generated Title: {arabic_title}")
                            link = publish_to_wp(arabic_title, content, fid)
                            if link:
                                print(f"   âœ… Published: {link}")
                                mark_published(entry.link, entry.title)
                    
                    time.sleep(10) 
            except Exception as e: print(f"   âš ï¸ Feed Error: {str(e)[:50]}")
        
        print("ğŸ’¤ Short Rest (10 min)...")
        time.sleep(600)

if __name__ == "__main__":
    main()
