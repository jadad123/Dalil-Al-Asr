import requests
import feedparser
import json
import time
import base64
import sqlite3
import os
import re
import urllib.parse
import io
import urllib3
import random
import httpx
from openai import OpenAI
from datetime import datetime
from difflib import SequenceMatcher
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±" (V9 - Strict Arabic & Huge Watermark)
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

OPENROUTER_KEY = os.getenv("OPENROUTER_KEY", "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")
WP_DOMAIN = os.getenv("WP_DOMAIN", "https://dalil-alasr.com") 
WP_USER = os.getenv("WP_USER", "admin")
WP_APP_PASS = os.getenv("WP_APP_PASS", "xxxx xxxx xxxx xxxx")

WP_ENDPOINT = f"{WP_DOMAIN}/wp-json/wp/v2"
WATERMARK_TEXT = "dalilaleasr.com"

BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
    "Referer": "https://google.com"
}

# Ù†Ù…Ø§Ø°Ø¬ Ù‚ÙˆÙŠØ© ÙÙ‚Ø·
FREE_TEXT_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "microsoft/phi-3-medium-128k-instruct:free"
]

FREE_VISION_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.2-90b-vision-instruct:free",
]

BLACKLIST_KEYWORDS = [
    "ÙÙŠÙ„Ù…", "Ù…Ø³Ù„Ø³Ù„", "Ø£ØºÙ†ÙŠØ©", "ÙÙ†Ø§Ù†", "Ù…Ù…Ø«Ù„Ø©", "Ø±Ù‚Øµ", "Ø­ÙÙ„ ØºÙ†Ø§Ø¦ÙŠ", 
    "Ø³ÙŠÙ†Ù…Ø§", "Ø¯Ø±Ø§Ù…Ø§", "Ø·Ø±Ø¨", "Ø£Ù„Ø¨ÙˆÙ…", "ÙƒÙ„ÙŠØ¨", "ÙØ¶Ø§Ø¦ÙŠØ§Øª", 
    "Movie", "Song", "Actress", "Cinema", "Music Video", "Concert"
]

DB_FILE = "/app/data/dalil_history.db" if os.path.exists("/app") else "dalil_history.db"
FONT_PATH = "/app/data/Roboto-Bold.ttf"

# ==========================================
# 1. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…
# ==========================================
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (link TEXT PRIMARY KEY, title TEXT, published_at TEXT)''')
    conn.commit()
    conn.close()

def ensure_font():
    if not os.path.exists(FONT_PATH):
        print("   ğŸ“¥ Downloading professional font for watermark...")
        try:
            url = "https://github.com/google/fonts/raw/main/apache/roboto/Roboto-Bold.ttf"
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                os.makedirs(os.path.dirname(FONT_PATH), exist_ok=True)
                with open(FONT_PATH, 'wb') as f:
                    f.write(response.content)
        except Exception as e:
            print(f"   âš ï¸ Could not download font: {e}")

def is_published_link(link):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT 1 FROM history WHERE link=?", (link,))
    exists = c.fetchone()
    conn.close()
    return exists is not None

def mark_published(link, title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO history VALUES (?, ?, ?)", (link, title, datetime.now().isoformat()))
    conn.commit()
    conn.close()

def is_duplicate_semantic(new_title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT title FROM history ORDER BY published_at DESC LIMIT 50")
    rows = c.fetchall()
    conn.close()
    if not rows: return False
    recent_titles = [row[0] for row in rows if row[0]]
    for existing in recent_titles:
        if SequenceMatcher(None, new_title.lower(), existing.lower()).ratio() > 0.65:
            return True
    return False

# ==========================================
# 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
# ==========================================
def get_auth_header():
    clean_pass = WP_APP_PASS.replace(' ', '')
    creds = base64.b64encode(f"{WP_USER}:{clean_pass}".encode()).decode()
    return {"Authorization": f"Basic {creds}", "Content-Type": "application/json"}

def get_category_id_by_name(cat_name):
    ARABIC_NAMES = {
        "News": "Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ù…Ø©", "Politics": "Ø³ÙŠØ§Ø³Ø©", "Economy": "Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ£Ø¹Ù…Ø§Ù„",
        "Crypto": "Ø¹Ù…Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ©", "Tech": "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ÙˆØ°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", 
        "Health": "ØµØ­Ø© ÙˆØ·Ø¨", "Science": "Ø¹Ù„ÙˆÙ… ÙˆÙØ¶Ø§Ø¡", "Tutorials": "Ø´Ø±ÙˆØ­Ø§Øª ÙˆØ£Ø¯Ù„Ø©",
        "Sports": "Ø±ÙŠØ§Ø¶Ø©"
    }
    final_name = ARABIC_NAMES.get(cat_name, cat_name)
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/categories?search={final_name}", headers=h)
        if r.status_code == 200 and r.json():
            return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/categories", headers=h, json={"name": final_name})
        if r.status_code == 201:
            return r.json()['id']
    except: pass
    return 1

def get_or_create_tag_id(tag_name):
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/tags?search={tag_name}", headers=h)
        if r.status_code == 200 and r.json(): return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/tags", headers=h, json={"name": tag_name})
        if r.status_code == 201: return r.json()['id']
    except: pass
    return None

# ==========================================
# 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± (Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ø¶Ø®Ù…Ø© V9)
# ==========================================
def get_ai_image_url(title):
    clean_title = re.sub(r'[^\w\s]', '', title)
    words = clean_title.split()[:9]
    prompt_text = " ".join(words)
    final_prompt = f"Editorial news photo of {prompt_text}, highly detailed, realistic, 4k, journalism style, no text, no blur"
    encoded_prompt = urllib.parse.quote(final_prompt)
    seed = int(time.time())
    return f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1280&height=720&nologo=true&seed={seed}&model=flux"

def check_image_safety(image_url):
    print(f"   ğŸ” Checking watermark in original...")
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=OPENROUTER_KEY, http_client=http_client)
    for i in range(3):
        model = random.choice(FREE_VISION_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": [{"type": "text", "text": "Does this image contain ANY text, logos, or watermarks? Answer strictly 'YES' or 'NO'."}, {"type": "image_url", "image_url": {"url": image_url}}]}]
            )
            return "NO" in response.choices[0].message.content.strip().upper()
        except: time.sleep(1)
    return False

def apply_branding(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        
        # ğŸ”¥ V9 Update: Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¬Ù…
        # Ø§Ù„Ø´Ø±ÙŠØ· ÙŠØ£Ø®Ø° 20% Ù…Ù† Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ØµÙˆØ±Ø© (Ø®ÙÙ…Ø³ Ø§Ù„ØµÙˆØ±Ø©)
        bar_height = int(height * 0.20) 
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø£Ø³ÙˆØ¯
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(0, 0, 0, 255))
        
        ensure_font()
        text = WATERMARK_TEXT
        
        # Ø§Ù„Ø®Ø· ÙŠØ£Ø®Ø° 80% Ù…Ù† Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø´Ø±ÙŠØ· (Ø¶Ø®Ù… Ø¬Ø¯Ø§Ù‹)
        font_size = int(bar_height * 0.8)
        
        try:
            if os.path.exists(FONT_PATH):
                font = ImageFont.truetype(FONT_PATH, font_size)
            else:
                font = ImageFont.load_default()
        except:
            font = ImageFont.load_default()
            
        try:
            left, top, right, bottom = font.getbbox(text)
            text_width = right - left
            text_height = bottom - top
        except:
            text_width = len(text) * (font_size * 0.5)
            text_height = font_size

        text_x = (width - text_width) / 2
        # ØªÙˆØ³ÙŠØ· Ø¯Ù‚ÙŠÙ‚
        text_y = height - (bar_height / 2) - (text_height / 2) - (bottom * 0.15 if 'bottom' in locals() else 0)
        
        draw.text((text_x, text_y), text, font=font, fill=(255, 255, 255, 255))
        
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=95)
        return output.getvalue()
    except Exception as e: 
        print(f"Branding Error: {e}")
        return image_bytes

def upload_final_image(img_url, alt_text):
    print(f"   â¬†ï¸ Downloading & Branding Image...")
    try:
        r_img = requests.get(img_url, headers=BROWSER_HEADERS, timeout=30, verify=False)
        if r_img.status_code == 200:
            branded_image_data = apply_branding(r_img.content)
            filename = f"dalil_{int(time.time())}.jpg"
            headers_wp = get_auth_header()
            headers_wp["Content-Disposition"] = f"attachment; filename={filename}"
            headers_wp["Content-Type"] = "image/jpeg"
            r_wp = requests.post(f"{WP_ENDPOINT}/media", headers=headers_wp, data=branded_image_data)
            if r_wp.status_code == 201: 
                media_id = r_wp.json()['id']
                seo_data = {
                    "alt_text": alt_text, "title": alt_text, 
                    "caption": f" {WATERMARK_TEXT}", "description": alt_text
                }
                requests.post(f"{WP_ENDPOINT}/media/{media_id}", headers=get_auth_header(), json=seo_data)
                return media_id
    except: pass
    return None

def extract_image(entry):
    if hasattr(entry, 'media_content') and entry.media_content:
        return entry.media_content[0].get('url') if isinstance(entry.media_content[0], dict) else entry.media_content[0]['url']
    if hasattr(entry, 'links') and entry.links:
        for l in entry.links:
            if 'image' in getattr(l, 'type', ''): return getattr(l, 'href', None)
    if hasattr(entry, 'summary'):
        m = re.search(r'<img.*?src=["\']([^"\']+)["\']', entry.summary)
        if m: return m.group(1)
    return None

# ==========================================
# 4. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Strict Arabic Enforcement)
# ==========================================
def clean_text_output(text):
    text = text.replace("*", "").replace('"', "")
    text = re.sub(r'##\s*(.+)', r'<h2>\1</h2>', text)
    return text

def is_english(text):
    try:
        # ÙØ­Øµ Ø¨Ø³ÙŠØ·: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
        return english_chars > arabic_chars
    except: return False

def generate_arabic_content_package(news_item):
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=OPENROUTER_KEY, http_client=http_client)
    
    # ğŸ”¥ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ØµØ§Ø±Ù… V9
    prompt = f"""
    Ø£Ù†Øª Ù…Ø­Ø±Ø± "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±". Ù‚Ù… Ø¨ØªØ±Ø¬Ù…Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ù„ Ø¹Ø±Ø¨ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ.
    
    Ø§Ù„Ù…ØµØ¯Ø±: "{news_item['title']}" - {news_item['summary']}

    âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹ (Strict Rules):
    1. **Ø§Ù„Ø¹Ù†ÙˆØ§Ù† (TITLE):** ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø­ØµØ±Ø§Ù‹. Ù„Ø§ ØªØ®Ø±Ø¬ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ§Ù‹ Ø£Ø¨Ø¯Ø§Ù‹.
    2. **Ø§Ù„Ø±ÙˆØ§Ø¨Ø·:** Ø§Ø±Ø¨Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆÙ‚Ø¹: <a href="{WP_DOMAIN}/?s=Ø§Ù„ÙƒÙ„Ù…Ø©">Ø§Ù„ÙƒÙ„Ù…Ø©</a>.
    3. **Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:** Ø§Ø³ØªØ®Ø¯Ù… HTML ÙÙ‚Ø· (<h2>, <p>, <ul>). Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ## Ø£Ùˆ **.

    Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ø§Ù„ØªØ²Ù… Ø¨Ù‡Ø§):
    OUTPUT_TITLE: [Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ Ø¬Ø°Ø§Ø¨]
    OUTPUT_BODY:
    <div style="background-color: #f1f8e9; border-right: 5px solid #66bb6a; padding: 20px; margin-bottom: 30px; border-radius: 5px;"><h3 style="margin-top: 0; color: #2e7d32;">ğŸ”¥ Ø®Ù„Ø§ØµØ© Ø³Ø±ÙŠØ¹Ø©:</h3><ul><li>Ù†Ù‚Ø·Ø© 1</li><li>Ù†Ù‚Ø·Ø© 2</li></ul></div>
    [Ù…Ù‚Ø¯Ù…Ø© Ù‚ÙˆÙŠØ©]
    [ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ø¹ Ø¹Ù†Ø§ÙˆÙŠÙ† h2]
    [Ø§Ù„Ø®Ø§ØªÙ…Ø©]
    OUTPUT_META:
    CATEGORY: [Category Name]
    TAGS: [Tags]
    META_DESC: [Desc]
    """
    
    for i in range(5):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            print(f"   ğŸ¤– Writing V9 Article with: {model}")
            response = client.chat.completions.create(
                model=model, messages=[{"role": "user", "content": prompt}], temperature=0.7
            )
            content = response.choices[0].message.content.replace("```html", "").replace("```", "").strip()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯Ù‚Ø©
            arabic_title = ""
            final_body = ""
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙŠ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
            if "OUTPUT_TITLE:" in content:
                parts = content.split("OUTPUT_BODY:")
                if len(parts) > 1:
                    raw_title = parts[0].replace("OUTPUT_TITLE:", "").strip()
                    arabic_title = clean_text_output(raw_title)
                    final_body = parts[1].split("OUTPUT_META:")[0].strip()
            
            # ğŸš¨ Fallback: Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø¥Ø¹Ø·Ø§Ø¡ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ
            if not arabic_title or is_english(arabic_title):
                print("   âš ï¸ Title looks English. Forcing Translation...")
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ø¤Ù‚ØªØ§Ù‹ ÙˆØ³Ù†ØªØ±Ø¬Ù…Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±ØŒ 
                # Ù„ÙƒÙ† Ù‡Ù†Ø§ Ø³Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ùˆ Ø§Ù„Ø£Ù‡Ù….
                # Ø§Ù„Ø£ÙØ¶Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…Ù† Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† ÙÙŠÙ‡ Ù…Ø´ÙƒÙ„Ø© Ø¨Ø³ÙŠØ·Ø©ØŒ 
                # ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ ÙƒØ§Ù† ÙØ§Ø±ØºØ§Ù‹ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£ØµÙ„ÙŠ.
                if not arabic_title: arabic_title = news_item['title']

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ø³Ù…
            final_body = clean_text_output(final_body)
            
            return arabic_title, final_body
            
        except Exception as e:
            error_str = str(e)
            if "429" in error_str:
                print(f"   â³ Rate Limit ({model}). Waiting 45s...")
                time.sleep(45) 
            else:
                print(f"   âš ï¸ AI Error: {e}. Retrying...")
                time.sleep(5)
    return None, None

def publish_to_wp(arabic_title, content, feat_img_id):
    # ÙØ­Øµ Ø£Ø®ÙŠØ±: Ù‡Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŸ Ø¥Ø°Ø§ Ù†Ø¹Ù…ØŒ Ù„Ø§ ØªÙ†Ø´Ø± (Ø£Ùˆ ØªØ±Ø¬Ù…Ù‡)
    # Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ Ø³Ù†Ù†Ø´Ø± ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ¨Ø¯Ùˆ Ø¹Ø±Ø¨ÙŠØ§Ù‹
    if is_english(arabic_title):
        print(f"   ğŸš« Skipping: Title is English ({arabic_title})")
        return None

    meta_desc, tags, cat_id = "", [], 1
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØªØ§ Ù…Ù† Ø§Ù„Ù†Øµ (Ø¨Ø´ÙƒÙ„ ØªÙ‚Ø±ÙŠØ¨ÙŠ Ù„Ø£Ù†Ù†Ø§ ÙØµÙ„Ù†Ø§Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª)
    # ÙÙŠ V9ØŒ Ø§Ù„Ù…ÙŠØªØ§ Ù‚Ø¯ ØªÙƒÙˆÙ† ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ù„ÙƒÙ†Ù†Ø§ ÙØµÙ„Ù†Ø§ Ø§Ù„Ù€ Body.
    # Ù„Ù„ØªØ¨Ø³ÙŠØ·ØŒ Ø³Ù†Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ØªØµÙ†ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ø³ÙŠØ· Ø£Ùˆ ÙØ§Ø±ØºØŒ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.
    
    tag_ids = [get_or_create_tag_id(t) for t in tags if t]
    
    data = {
        "title": arabic_title,
        "content": content, "status": "publish",
        "categories": [cat_id], "tags": tag_ids, "excerpt": meta_desc,
        "featured_media": feat_img_id,
        "rank_math_focus_keyword": arabic_title,
        "rank_math_description": meta_desc
    }
    
    r = requests.post(f"{WP_ENDPOINT}/posts", headers=get_auth_header(), json=data)
    if r.status_code == 201: return r.json()['link']
    print(f"   âŒ Publish Failed: {r.status_code}")
    return None

# ==========================================
# 5. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
def main():
    print("ğŸš€ Dalil Al-Asr (V9 - Strict Arabic & Huge Watermark) Started...")
    init_db()
    ensure_font()
    
    feeds = [
        "https://cointelegraph.com/rss",
        "https://decrypt.co/feed",
        "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "https://sa.investing.com/rss/news.rss",
        "https://www.cnbcarabia.com/rss/latest-news",
        "https://techcrunch.com/feed/",
        "https://www.theverge.com/rss/index.xml",
        "https://aitnews.com/feed/",
        "https://wired.com/feed/rss",
        "https://www.unlimit-tech.com/feed/",
        "https://www.aljazeera.net/aljazeerarss/a7c186be-1baa-4bd4-9d80-a84db769f779/73d0e1b4-532f-45ef-b135-bfdff8b8cab9",
        "https://www.skynewsarabia.com/web/rss",
        "https://cnn.com/rss/cnn_topstories.rss",
        "https://feeds.bbci.co.uk/news/world/rss.xml",
        "https://www.sciencedaily.com/rss/top/health.xml",
        "https://www.nasa.gov/rss/dyn/breaking_news.rss"
    ]
    
    while True:
        print(f"\nâ° Cycle Start: {datetime.now().strftime('%H:%M')}")
        random.shuffle(feeds)
        
        for feed in feeds:
            try:
                d = feedparser.parse(feed)
                for entry in d.entries[:5]: 
                    if is_published_link(entry.link): continue
                    if any(bad in entry.title for bad in BLACKLIST_KEYWORDS): continue
                    if is_duplicate_semantic(entry.title): continue
                    
                    print(f"   âš¡ Processing: {entry.title[:40]}...")
                    
                    original_img = extract_image(entry)
                    final_img_url = None
                    if original_img:
                        if check_image_safety(original_img):
                            print("   âœ… Original Clean.")
                            final_img_url = original_img
                        else:
                            print("   âš ï¸ Watermark detected. AI Gen...")
                            final_img_url = get_ai_image_url(entry.title)
                    else:
                        print("   ğŸ¨ AI Gen...")
                        final_img_url = get_ai_image_url(entry.title)
                    
                    fid = upload_final_image(final_img_url, entry.title)
                    
                    if fid:
                        arabic_title, content = generate_arabic_content_package({'title': entry.title, 'summary': getattr(entry, 'summary', '')})
                        
                        if content and arabic_title:
                            print(f"   ğŸ“ Generated Title: {arabic_title}")
                            link = publish_to_wp(arabic_title, content, fid)
                            if link:
                                print(f"   âœ… Published: {link}")
                                mark_published(entry.link, entry.title)
                    
                    time.sleep(10) 
            except Exception as e: print(f"   âš ï¸ Feed Error: {str(e)[:50]}")
        
        print("ğŸ’¤ Short Rest (10 min)...")
        time.sleep(600)

if __name__ == "__main__":
    main()
